{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "import math\n",
    "from nltk.classify import NaiveBayesClassifier\n",
    "import collections\n",
    "import nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Let's pull in the tweets from the extracted ICE tweets\n",
    "df = pd.read_csv('https://s3.amazonaws.com/d4d-public/public/ice_extract.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>user_followers</th>\n",
       "      <th>created</th>\n",
       "      <th>user_name</th>\n",
       "      <th>text</th>\n",
       "      <th>user_created</th>\n",
       "      <th>id_str</th>\n",
       "      <th>user_description</th>\n",
       "      <th>original_id</th>\n",
       "      <th>original_name</th>\n",
       "      <th>friends_count</th>\n",
       "      <th>retweet_count</th>\n",
       "      <th>hashtags</th>\n",
       "      <th>retweet</th>\n",
       "      <th>user_location</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>92298</td>\n",
       "      <td>2017-02-16 22:53:31.000000</td>\n",
       "      <td>IndigndeVerdad</td>\n",
       "      <td>LIVE NYC #ICERaids https://t.co/PZnleLAkpv</td>\n",
       "      <td>2013-03-21 13:02:04.000000</td>\n",
       "      <td>832362301672009728</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>90376</td>\n",
       "      <td>0</td>\n",
       "      <td>[\"ICERaids\"]</td>\n",
       "      <td>N</td>\n",
       "      <td>Madrid</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>18927</td>\n",
       "      <td>2017-02-16 22:53:44.000000</td>\n",
       "      <td>MaketheRoadNY</td>\n",
       "      <td>Antonio Alarcon from MRNY introduces passionat...</td>\n",
       "      <td>2010-05-07 17:35:33.000000</td>\n",
       "      <td>832362355581448192</td>\n",
       "      <td>Building power of Latinx &amp; working class commu...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2882</td>\n",
       "      <td>0</td>\n",
       "      <td>[\"ICERaids\", \"freedaniel\"]</td>\n",
       "      <td>N</td>\n",
       "      <td>New York City</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>16479</td>\n",
       "      <td>2017-02-16 22:53:56.000000</td>\n",
       "      <td>sickjew</td>\n",
       "      <td>RT @altochulo: ¡Trump escucha, estamos en la l...</td>\n",
       "      <td>2009-08-13 16:41:02.000000</td>\n",
       "      <td>832362403845251072</td>\n",
       "      <td>Health care is a human right. // backup accoun...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>12004</td>\n",
       "      <td>0</td>\n",
       "      <td>[\"FreeDaniel\", \"ICERaids\"]</td>\n",
       "      <td>N</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>16479</td>\n",
       "      <td>2017-02-16 22:54:06.000000</td>\n",
       "      <td>sickjew</td>\n",
       "      <td>RT @altochulo: Getting packed here to say #Fre...</td>\n",
       "      <td>2009-08-13 16:41:02.000000</td>\n",
       "      <td>832362447231127554</td>\n",
       "      <td>Health care is a human right. // backup accoun...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>12004</td>\n",
       "      <td>0</td>\n",
       "      <td>[\"FreeDaniel\", \"ICERaids\"]</td>\n",
       "      <td>N</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>129</td>\n",
       "      <td>2017-02-16 22:54:08.000000</td>\n",
       "      <td>Babar_392</td>\n",
       "      <td>RT @MaketheRoadNY: Staten Island--where recent...</td>\n",
       "      <td>2011-11-23 15:46:54.000000</td>\n",
       "      <td>832362454650912768</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>346</td>\n",
       "      <td>0</td>\n",
       "      <td>[\"ICERaids\"]</td>\n",
       "      <td>N</td>\n",
       "      <td>Virginia, USA</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id  user_followers                     created       user_name  \\\n",
       "0   1           92298  2017-02-16 22:53:31.000000  IndigndeVerdad   \n",
       "1   2           18927  2017-02-16 22:53:44.000000   MaketheRoadNY   \n",
       "2   3           16479  2017-02-16 22:53:56.000000         sickjew   \n",
       "3   4           16479  2017-02-16 22:54:06.000000         sickjew   \n",
       "4   5             129  2017-02-16 22:54:08.000000       Babar_392   \n",
       "\n",
       "                                                text  \\\n",
       "0         LIVE NYC #ICERaids https://t.co/PZnleLAkpv   \n",
       "1  Antonio Alarcon from MRNY introduces passionat...   \n",
       "2  RT @altochulo: ¡Trump escucha, estamos en la l...   \n",
       "3  RT @altochulo: Getting packed here to say #Fre...   \n",
       "4  RT @MaketheRoadNY: Staten Island--where recent...   \n",
       "\n",
       "                 user_created              id_str  \\\n",
       "0  2013-03-21 13:02:04.000000  832362301672009728   \n",
       "1  2010-05-07 17:35:33.000000  832362355581448192   \n",
       "2  2009-08-13 16:41:02.000000  832362403845251072   \n",
       "3  2009-08-13 16:41:02.000000  832362447231127554   \n",
       "4  2011-11-23 15:46:54.000000  832362454650912768   \n",
       "\n",
       "                                    user_description  original_id  \\\n",
       "0                                                NaN          NaN   \n",
       "1  Building power of Latinx & working class commu...          NaN   \n",
       "2  Health care is a human right. // backup accoun...          NaN   \n",
       "3  Health care is a human right. // backup accoun...          NaN   \n",
       "4                                                NaN          NaN   \n",
       "\n",
       "   original_name  friends_count  retweet_count                    hashtags  \\\n",
       "0            NaN          90376              0                [\"ICERaids\"]   \n",
       "1            NaN           2882              0  [\"ICERaids\", \"freedaniel\"]   \n",
       "2            NaN          12004              0  [\"FreeDaniel\", \"ICERaids\"]   \n",
       "3            NaN          12004              0  [\"FreeDaniel\", \"ICERaids\"]   \n",
       "4            NaN            346              0                [\"ICERaids\"]   \n",
       "\n",
       "  retweet  user_location  \n",
       "0       N         Madrid  \n",
       "1       N  New York City  \n",
       "2       N            NaN  \n",
       "3       N            NaN  \n",
       "4       N  Virginia, USA  "
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Let's take a look at it\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# OK, now that we have that, let's save it to a text file. This will help get a quick way to look at the text\n",
    "df['text'].to_csv('training_data/test.txt', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "Now we're going to completely switch gears and build a model to determine whether a statement is positive or negative. We're going to use quotes from movies review, which is a bit of a stretch, but it's a place to start. This method is from Andy Bromberg's webpage. My goal is to build on it, but for now let's just try to get it working"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#I have two files, one of positive statements (from movie reviews) and the other with negative. To run this\n",
    "#download the files from Andy Bromberg's GitHub page: https://github.com/abromberg/sentiment_analysis_python\n",
    "positive_statements = 'C:/Users/HMGSYS/Google Drive/JupyterNotebooks/Data4Democracy/training_data/pos.txt'\n",
    "negative_statements = 'C:/Users/HMGSYS/Google Drive/JupyterNotebooks/Data4Democracy/training_data/neg.txt'\n",
    "#And I also have our file we just created with ICERaids tweets\n",
    "test_statements = 'C:/Users/HMGSYS/Google Drive/JupyterNotebooks/Data4Democracy/training_data/test.txt'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#creates a feature selection mechanism that uses all words\n",
    "def make_full_dict(words):\n",
    "    return dict([(word, True) for word in words])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Let's open the files and create lists with all the words in them\n",
    "posFeatures = []\n",
    "negFeatures = []\n",
    "mytestFeatures = []\n",
    "with open(positive_statements, 'r') as posSentences:\n",
    "    for i in posSentences:\n",
    "        posWords = re.findall(r\"[\\w']+|[.,!?;]\", i.rstrip())\n",
    "        posWords = [make_full_dict(posWords), 'pos']\n",
    "        posFeatures.append(posWords)\n",
    "with open(negative_statements, 'r') as negSentences:\n",
    "    for i in negSentences:\n",
    "        negWords = re.findall(r\"[\\w']+|[.,!?;]\", i.rstrip())\n",
    "        negWords = [make_full_dict(negWords), 'neg']\n",
    "        negFeatures.append(negWords)\n",
    "# Now let's do the same with our test data\n",
    "with open(test_statements, 'r') as mytestSentences:\n",
    "    for i in mytestSentences:\n",
    "        mytestWords = re.findall(r\"[\\w']+|[.,!?;]\", i.rstrip())\n",
    "        # We're going to label them as positive so we can check the accuracy\n",
    "        mytestWords = [make_full_dict(mytestWords), 'pos']\n",
    "        mytestFeatures.append(mytestWords)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[{',': True,\n",
       "   '.': True,\n",
       "   '21st': True,\n",
       "   'a': True,\n",
       "   'and': True,\n",
       "   'arnold': True,\n",
       "   'be': True,\n",
       "   \"century's\": True,\n",
       "   'claud': True,\n",
       "   'conan': True,\n",
       "   'damme': True,\n",
       "   'destined': True,\n",
       "   'even': True,\n",
       "   'going': True,\n",
       "   'greater': True,\n",
       "   \"he's\": True,\n",
       "   'is': True,\n",
       "   'jean': True,\n",
       "   'make': True,\n",
       "   'new': True,\n",
       "   'or': True,\n",
       "   'rock': True,\n",
       "   'schwarzenegger': True,\n",
       "   'segal': True,\n",
       "   'splash': True,\n",
       "   'steven': True,\n",
       "   'than': True,\n",
       "   'that': True,\n",
       "   'the': True,\n",
       "   'to': True,\n",
       "   'van': True},\n",
       "  'pos'],\n",
       " [{'.': True,\n",
       "   'a': True,\n",
       "   'adequately': True,\n",
       "   'cannot': True,\n",
       "   'co': True,\n",
       "   'column': True,\n",
       "   'continuation': True,\n",
       "   'describe': True,\n",
       "   'director': True,\n",
       "   'earth': True,\n",
       "   'elaborate': True,\n",
       "   'expanded': True,\n",
       "   'gorgeously': True,\n",
       "   'huge': True,\n",
       "   'is': True,\n",
       "   'j': True,\n",
       "   \"jackson's\": True,\n",
       "   'lord': True,\n",
       "   'middle': True,\n",
       "   'of': True,\n",
       "   'peter': True,\n",
       "   'r': True,\n",
       "   'rings': True,\n",
       "   'so': True,\n",
       "   'that': True,\n",
       "   'the': True,\n",
       "   \"tolkien's\": True,\n",
       "   'trilogy': True,\n",
       "   'vision': True,\n",
       "   'words': True,\n",
       "   'writer': True},\n",
       "  'pos']]"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Let's take a quick look at our result\n",
    "posFeatures[0:2]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we have two big lists: posFeatures and negFeatures. These are lists of lists, where each internal list is a collection of all the words that are in a positive movie review. Inside those lists are two things: a dictionary and a string. The dictionary is a mapping of every word in the review to a boolean (True). The string is either 'pos' or 'neg' depending on which corpus it came from."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#selects 3/4 of the features to be used for training and 1/4 to be used for testing\n",
    "posCutoff = int(math.floor(len(posFeatures)*3/4))\n",
    "negCutoff = int(math.floor(len(negFeatures)*3/4))\n",
    "mytestCutoff = int(math.floor(len(mytestFeatures)*3/4))\n",
    "#Now this is a bit tricky because we have testFeatures and mytestFeatures. testFeatures is from the Bromberg model\n",
    "#mytestFeatures is me throwing our test (ICERaids) tweets into the same process\n",
    "trainFeatures = posFeatures[:posCutoff] + negFeatures[:negCutoff]\n",
    "testFeatures = posFeatures[posCutoff:] + negFeatures[negCutoff:]\n",
    "#This last one doesn't change\n",
    "mytestFeatures = mytestFeatures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# We'll start with a Naive Bayes Classifier. There's a lot more we could do here but it's a start\n",
    "classifier = NaiveBayesClassifier.train(trainFeatures)\n",
    "\n",
    "#initiates referenceSets and testSets\n",
    "referenceSets = collections.defaultdict(set)\n",
    "testSets = collections.defaultdict(set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# puts correctly labeled sentences in referenceSets and the predictively labeled version in testsets\n",
    "for i, (features, label) in enumerate(testFeatures):\n",
    "    referenceSets[label].add(i)\n",
    "    predicted = classifier.classify(features)\n",
    "    testSets[predicted].add(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train on 7997 instances, test on 2666 instances\n",
      "accuracy: 0.7730682670667667\n",
      "pos precision: 0.7875197472353871\n",
      "pos recall: 0.7479369842460615\n",
      "neg precision: 0.76\n",
      "neg recall: 0.7981995498874719\n"
     ]
    }
   ],
   "source": [
    "#prints metrics to show how well the feature selection did\n",
    "print ('train on %d instances, test on %d instances' % (len(trainFeatures), len(testFeatures)))\n",
    "print ('accuracy:', nltk.classify.util.accuracy(classifier, testFeatures))\n",
    "print ('pos precision:', nltk.scores.precision(referenceSets['pos'], testSets['pos']))\n",
    "print ('pos recall:', nltk.scores.recall(referenceSets['pos'], testSets['pos']))\n",
    "print ('neg precision:', nltk.scores.precision(referenceSets['neg'], testSets['neg']))\n",
    "print ('neg recall:', nltk.scores.recall(referenceSets['neg'], testSets['neg']))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we have a Naive Bayes Classifier that looks at words in movie reviews and predicts whether that review is positive or negative. As it stands, the accuracy is only 77%, which means that we're on the right path (better than just guessing) but it's not very impressive. Still, we have a bunch of words that correlate with a positive or negative review. Let's take a look at some of the most predictive words and see what we've got"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Most Informative Features\n",
      "              engrossing = True              pos : neg    =     17.0 : 1.0\n",
      "                   quiet = True              pos : neg    =     15.7 : 1.0\n",
      "                mediocre = True              neg : pos    =     13.7 : 1.0\n",
      "               absorbing = True              pos : neg    =     13.0 : 1.0\n",
      "                portrait = True              pos : neg    =     12.4 : 1.0\n",
      "                   flaws = True              pos : neg    =     12.3 : 1.0\n",
      "               inventive = True              pos : neg    =     12.3 : 1.0\n",
      "              refreshing = True              pos : neg    =     12.3 : 1.0\n",
      "                 triumph = True              pos : neg    =     11.7 : 1.0\n",
      "            refreshingly = True              pos : neg    =     11.7 : 1.0\n"
     ]
    }
   ],
   "source": [
    "classifier.show_most_informative_features(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Those words aren't great for determining someone's thoughts about ICE raids. \"Engrossing\" is definintely a movie word. It's also interesting that \"flaws\" is such a positive word."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "OK, now for the moment of truth - let's see what percentage of tweets about the ICE raids this model classifies as positive. Remember, it only got 77% right for movie reviews, so this could be wildly inaccurate."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This model predicts that 67.6% of tweets about the ICE raids have been positive\n"
     ]
    }
   ],
   "source": [
    "print ('This model predicts that {:.1%} of tweets about the ICE raids have been positive'\n",
    "       .format(nltk.classify.util.accuracy(classifier, mytestFeatures)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Well, we got significantly over 50%. Can we conclude that the majority of tweets about this have been positive? Perhaps. We could also check it every month or so to see how this number changes over time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
